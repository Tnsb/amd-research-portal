source_id,title,authors,year,source_type,venue,url_or_doi,raw_path,processed_path,tags,relevance_note
RAGAS2023,RAGAS: Automated Evaluation of Retrieval Augmented Generation,Shah et al.,2023,paper,arXiv,https://arxiv.org/abs/2309.15217,data/raw/RAGAS2023.pdf,data/processed/RAGAS2023.txt,RAG;evaluation;faithfulness;reference-free,Reference-free RAG evaluation framework; defines faithfulness answer relevance context relevance metrics.
ARES2023,ARES: An Automated Evaluation Framework for Retrieval-Augmented Generation Systems,Saad-Falcon et al.,2023,paper,NAACL 2024,https://arxiv.org/abs/2311.09476,data/raw/ARES2023.pdf,data/processed/ARES2023.txt,RAG;evaluation;LM judges;faithfulness,Automated RAG evaluation with LM judges; assesses context relevance answer faithfulness answer relevance.
RAG_Eval_Survey2024,Evaluation of Retrieval-Augmented Generation: A Survey,Zhu et al.,2024,paper,arXiv,https://arxiv.org/abs/2405.07437,data/raw/RAG_Eval_Survey2024.pdf,data/processed/RAG_Eval_Survey2024.txt,RAG;survey;evaluation;Auepora,Survey of RAG evaluation; Auepora framework; metrics for retrieval and generation including faithfulness.
FaithEval2024,FaithEval: Can Your Language Model Stay Faithful to Context Even If The Moon is Made of Marshmallows,Li et al.,2024,paper,arXiv,https://arxiv.org/abs/2410.03727,data/raw/FaithEval2024.pdf,data/processed/FaithEval2024.txt,faithfulness;benchmark;LLM,Benchmark for faithfulness across unanswerable inconsistent counterfactual contexts; 4.9K problems.
Hallucination_Survey2023,A Survey on Hallucination in Large Language Models: Principles Taxonomy Challenges and Open Questions,Zhang et al.,2023,paper,arXiv,https://arxiv.org/abs/2311.05232,data/raw/Hallucination_Survey2023.pdf,data/processed/Hallucination_Survey2023.txt,hallucination;survey;LLM,Comprehensive survey on hallucination; taxonomy detection methods benchmarks; foundational for faithfulness discussion.
FIB2022,Evaluating the Factual Consistency of Large Language Models Through News Summarization,Laban et al.,2022,paper,arXiv,https://arxiv.org/abs/2211.08412,data/raw/FIB2022.pdf,data/processed/FIB2022.txt,factual consistency;FIB;benchmark,Factual Inconsistency Benchmark (FIB); evaluates whether LLMs prefer consistent over inconsistent summaries.
BERTScore2019,BERTScore: Evaluating Text Generation with BERT,Tian et al.,2019,paper,ICLR 2020,https://arxiv.org/abs/1904.09675,data/raw/BERTScore2019.pdf,data/processed/BERTScore2019.txt,BERTScore;semantic similarity;evaluation,Semantic similarity metric using BERT; used for faithfulness evaluation; alternative to n-gram metrics.
SummaC2021,SummaC: Re-Visiting NLI-based Models for Inconsistency Detection in Summarization,Laban et al.,2021,paper,TACL,https://arxiv.org/abs/2111.09525,data/raw/SummaC2021.pdf,data/processed/SummaC2021.txt,NLI;faithfulness;summarization,NLI-based faithfulness detection for summarization; textual entailment for hallucination detection.
FactCC2020,Evaluating the Factual Consistency of Abstractive Summarization,Kryscinski et al.,2020,paper,EMNLP 2020,https://arxiv.org/abs/2005.00661,data/raw/FactCC2020.pdf,data/processed/FactCC2020.txt,QA-based;FactCC;faithfulness,QA-based factual consistency; FactCC benchmark; foundational work on faithfulness evaluation.
RAG_Survey_LLM2025,Retrieval Augmented Generation Evaluation in the Era of Large Language Models: A Comprehensive Survey,Various,2025,paper,arXiv,https://arxiv.org/abs/2504.14891,data/raw/RAG_Survey_LLM2025.pdf,data/processed/RAG_Survey_LLM2025.txt,RAG;survey;LLM;evaluation,Comprehensive RAG evaluation survey in LLM era; traditional and emerging metrics; benchmarks.
QASemConsistency2024,Localizing Factual Inconsistencies in Attributable Text Generation,Min et al.,2024,paper,arXiv,https://arxiv.org/abs/2410.07473,data/raw/QASemConsistency2024.pdf,data/processed/QASemConsistency2024.txt,QASem;localization;faithfulness,Fine-grained inconsistency localization; predicate-argument level; QASem formalism.
TRUE_Benchmark2023,Benchmarking Large Language Model Capabilities for Conditional Generation,Liusie et al.,2023,paper,arXiv,https://arxiv.org/abs/2305.09571,data/raw/TRUE_Benchmark2023.pdf,data/processed/TRUE_Benchmark2023.txt,TRUE;benchmark;conditional generation,TRUE benchmark; evaluates conditional generation; includes faithfulness tasks.
NLI_Faithfulness2023,With a Little Push NLI Models can Robustly and Efficiently Predict Faithfulness,Guerreiro et al.,2023,paper,ACL 2023,https://arxiv.org/abs/2304.05292,data/raw/NLI_Faithfulness2023.pdf,data/processed/NLI_Faithfulness2023.txt,NLI;faithfulness;TRUE,NLI models for faithfulness; data augmentation entailment/contradiction; strong on TRUE benchmark.
DALLEval2024,DALLEval: A Framework for Evaluating Text-to-Image Generation Models,Cho et al.,2023,paper,arXiv,https://arxiv.org/abs/2306.06504,data/raw/DALLEval2024.pdf,data/processed/DALLEval2024.txt,evaluation framework;faithfulness;multi-dimensional,Multi-dimensional evaluation framework; includes faithfulness dimension; applicable to evaluation design.
LongForm_Faithfulness2023,LongForm: Optimizing Instruction Tuning for Long Text Generation with Corpus Extraction,Guo et al.,2023,paper,arXiv,https://arxiv.org/abs/2305.14998,data/raw/LongForm_Faithfulness2023.pdf,data/processed/LongForm_Faithfulness2023.txt,long-form;instruction tuning;faithfulness,Long-form generation; touches on faithfulness in instruction following; evaluation considerations.
REPLUG2023,REPLUG: Retrieval-Augmented Black-Box Language Models,Shi et al.,2023,paper,arXiv,https://arxiv.org/abs/2301.12652,data/raw/REPLUG2023.pdf,data/processed/REPLUG2023.txt,RAG;black-box;retrieval,Retrieval-augmented black-box LMs; retrieval quality impacts generation; evaluation context.
REALM2020,REALM: Retrieval-Augmented Language Model Pre-Training,Guu et al.,2020,paper,ICML 2020,https://arxiv.org/abs/2002.08909,data/raw/REALM2020.pdf,data/processed/REALM2020.txt,RAG;pre-training;retrieval,Early RAG; knowledge retriever + generator; establishes retrieval-generation evaluation needs.
G-Eval2023,G-Eval: NLG Evaluation using GPT-4 with Better Human Alignment,Liu et al.,2023,paper,EMNLP 2023,https://arxiv.org/abs/2303.16634,data/raw/G-Eval2023.pdf,data/processed/G-Eval2023.txt,LLM-as-judge;evaluation;faithfulness,LLM-as-judge for NLG evaluation; includes faithfulness dimension; explores automated evaluation.
